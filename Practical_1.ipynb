{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Practical_1",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitEmmSt/Medical_Imaging/blob/main/Practical_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8sD1Sdz9RV",
        "outputId": "428283f4-81d5-4340-9fb9-2282396b3c96"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5lK9TuI0KVS",
        "outputId": "eef8356e-e7c0-4a3b-a8cc-117a483202c7"
      },
      "source": [
        "%cd /content/drive/MyDrive/Medical Imaging/practical_session_1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Medical Imaging/practical_session_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9IdVNYLz0c6"
      },
      "source": [
        "# <center>Biomedical Imaging</center><br><center>Practical session 1: Image formation and reconstruction  (12/10/2021)</center>\n",
        "***\n",
        "*Charlotte Thyssen, Jens Maebe, Stefaan Vandenberghe* <br>\n",
        "*MEDISIP, Ghent University* <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnvTlYr0z0dK"
      },
      "source": [
        "<font color=blue>Insert students names and IDs here</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgiJ_ZEez0dM"
      },
      "source": [
        "***\n",
        "# General\n",
        "In total, there will be 4 practical sessions. For every session you should hand in a report **in groups of 2**. These reports will count for 5 out of 20 points for the exam. The topics of the sessions:\n",
        "\n",
        "1. Image reconstruction in tomography, CT (25%)\t\n",
        "\n",
        "2. Monte Carlo simulations, SPECT (25%)\t\n",
        "\n",
        "3. Image processing part I (25%)\n",
        "\n",
        "4. Image processing part II (25%)\n",
        "\n",
        "***\n",
        "Report due 2 weeks after session\n",
        "\n",
        "\n",
        "- **Concise** and **to the point** answers to the questions\n",
        "\n",
        "- Show that you understood what was going on and what the purpose of the exercise was\n",
        "\n",
        "- Illustrate with figures \n",
        "\n",
        "- Hand in your notebook (also add the html file) via UFORA (UGent) or Canvas (VUB)\n",
        "\n",
        "***\n",
        "We are here to help you: ask questions!\n",
        "- During the sessions\n",
        "- Via mail:\n",
        "    - cathysse.thyssen@ugent.be\n",
        "    - jens.maebe@ugent.be\n",
        "    \n",
        "\n",
        "**Strict deadline for this session: 26 October 2021 at 23:59**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC_0IfCIz0dO"
      },
      "source": [
        "During the sessions, we will use **scikit-image**. This is a free python toolbox with a collection of algorithms for image processing. In image processing, all images are nd-arrays (2d if black/white flat image), so in order to be able to load these images. You should always import **numpy**.\n",
        "\n",
        "# 1. Image formation\n",
        "## 1.1 Fanbeam transform\n",
        "In a CT scanner, the photon source is an X-ray tube. To make things easier, we approximate it as an infinitesimally small point source (figure 1).\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><img src=\"images/CT_schematic.jpg\" width=\"300\"/><figcaption><center>(a)</center></figcaption></td>\n",
        "        <td><img src=\"images/CT_open.jpg\" width=\"300\"/><figcaption><center>(b)</center></figcaption></td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "<center><i>Figure 1: (a) The different parts of a CT-scanner. (b) The inside of a CT scanner with the different parts and coordinates indicated.</i></center>\n",
        "\n",
        "From this point source, photons are fired through the patient's body. The curved detector on the other side of the patient will detect the photons which have not been attenuated along their path through the body. Because we knew the number of fired photons ($I_0$), we can calculate the attenuation from the Beer-Lambert law:\n",
        "\\begin{equation}\n",
        "\tI=\\int I_0\\left(E\\right) e^{-\\int_0^L\\mu(\\vec{x},E) d\\vec{x}} dE,\n",
        "\\end{equation}\n",
        "\n",
        "with $I$ the number of detected photons (quanta) in a detector pixel, $E$ the photon energy (remember, X-rays generated by an X-ray tube are always polyenergetic!), $\\mu$ the attenuation coefficient and $\\vec{x}$ a vector representing the spatial coordinate along the line, from $0$ to $L$. If we ignore the energy spectrum for now and try to determine $\\int \\mu(\\vec{x}) d\\vec{x}$, we first have to calculate the log-attenuated values:\n",
        "\n",
        "\\begin{equation}\n",
        "\\int_0^L \\mu(\\vec{x}) d\\vec{x} = \\log\\left(I_0\\right) - \\log\\left( I \\right).\n",
        "\\end{equation} \n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><img src=\"images/fanbeam.jpg\" width=\"300\"/><figcaption><center>(a)</center></figcaption></td>\n",
        "        <td><img src=\"images/parbeam.jpg\" width=\"300\"/><figcaption><center>(b)</center></figcaption></td>\n",
        "    </tr>\n",
        "        <td><img src=\"images/fansino.jpg\" width=\"300\"/><figcaption><center>(c)</center></figcaption></td>\n",
        "        <td><img src=\"images/parsino.jpg\" width=\"300\"/><figcaption><center>(d)</center></figcaption></td>\n",
        "    <tr>\n",
        "</table>\n",
        "<center><i>Figure 2: (a) The geometry of a fanbeam projection, (b) parallel beam projection, (c) a sinogram obtained from a fanbeam, (d) and parallel beam projection.\n",
        "</i></center>\n",
        "\n",
        "These so-called path lengths are what will be used for the rest of the practicum session.\n",
        "\n",
        "The ideal path followed by each photon can be represented by a line connecting the X-ray source with the place of detection. All lines (for all detector pixels) for one rotation angle together form one fan beam projection (figure 2(a)). This represents one line in the sinogram. If we now rotate the source-detector pair around the patient and sample on different angles, a complete sinogram is obtained. \n",
        "\n",
        "This measured sinogram, containing data acquired from different angles, is the only data received from a CT scanner. This data can be used to directly reconstruct the original object in 3D. However, in this exercise lesson, we will reconstruct only from parallel projections and not from fan beam projections. Therefore, the fan beam projections have to be converted (a.k.a. rebinned) to parallel projection data.\n",
        "\n",
        "## 1.2 The radon transform\n",
        "Figure 2(c) and 2(d) respectively show sinograms obtained in fanbeam geometry and a parallel beam geometry. Forward projecting in a parallel beam geometry can be described mathematically by the Radon transform $R(\\theta,x^\\prime)$: \n",
        "\\begin{equation}\n",
        "\tR(\\theta,x^\\prime)= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)\\delta(x^\\prime - (x\\cos\\theta+y\\sin\\theta)) dx dy.\n",
        "\\end{equation}\n",
        "Here, $f(x,y)$ represents the distribution of the attenuation coefficients in the body.\n",
        "The Radon transform $R(\\theta=\\Theta,x\\prime=X^\\prime)$ can be interpreted as the sum (if we discretize $f(x,y)$ in pixels) of the attenuation coefficients at rotation angle $\\Theta$ along a line perpendicular to the $x^\\prime$-axis, crossing this axis at $X^\\prime$. $x^\\prime$ can be calculated from $\\theta$, $x$ and $y$ as:\n",
        "\\begin{equation}\n",
        "x^\\prime= x \\cos\\theta +y \\sin\\theta,\n",
        "\\end{equation}\n",
        "which is just a rotated $x$. These data can then be reconstructed by using the inverse of the Radon transform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SVKNAaDz0da"
      },
      "source": [
        "## <font color='blue'>Exercise 1: Parallel beam projection</font>\n",
        "In this exercise you will create a virtual CT scanner data. However, unlike in reality, we will assume a perfect parallel beam which allows us to use the Radon transform for this projection. For this exercise and the following, we will use the scikit-image package of python (https://scikit-image.org/).   \n",
        "\n",
        "Start by creating an empty 64$\\times$64 image (2D matrix) where you add a point (cluster of 2$\\times$2 pixels with value 1) somewhere off-center. Project this data over a 360$^\\circ$ angular range using 360 projection angles by making use of the `radon(...)` function from scikit-image.\n",
        "\n",
        "Repeat this with a 6 pixel long off-center 'line' instead of a point.\n",
        "\n",
        "\n",
        "### Remark\n",
        "Define the projection angles with the `np.linespace(...)` function from the numpy package. This will generate an array with evenly distributed angles over a given range.\n",
        "\n",
        "<font color='blue'>We expect to see the two images you used with their sinograms. Explain the differences you see between both sinograms and reinforce your answer by making use of overlapping profiles (line plots) of the sinograms at certain angles. </font>\n",
        "\n",
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S3snS1Lz0db"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzshOKL2z0dc"
      },
      "source": [
        "### Code for Exercise 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrQ2x5fz0dg"
      },
      "source": [
        "***\n",
        "## <font color='blue'>Exercise 2: the sinogram</font>\n",
        "To understand the content of a sinogram, we will take a closer look at the relation between an image and its sinogram. Therefore, start by making an image containing four points (each a cluster of 2$\\times$2 pixels). The first point should be in the center, the three other points should be located off-center, at different distances from the center. Make use of the `radon(...)` function in scikit-image to project the image to sinogram space.\n",
        "\n",
        "\n",
        "<font color='blue'>Plot the original image and show it together with its sinogram obtained from a 360◦ and a 180◦ angular range. Use 90 projection angles in both cases.\n",
        "\n",
        "Now answer these questions:\n",
        "- Why do we call this a sinogram?\n",
        "- What is the relation between the sinogram and the position in the original image?\n",
        "- Would you use the 360◦ or the 180◦ angular range when the number of projection angles is fixed? Why? </font>\n",
        "\n",
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL0JAHFz0di"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfMm8CM8z0dj"
      },
      "source": [
        "### Code for Exercise 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXP5Obj6z0dk"
      },
      "source": [
        "***\n",
        "## <font color='blue'>Exercise 3: the sinogram (continued)</font>\n",
        "To get an even better feel of what kind of data is included in a sinogram, download the file **Abdomen.bin** from Ufora and open it. This data is a slice of an in-vivo abdominal scan of a mouse, measured with a cone-beam micro-CT system in the Infinity lab. We already rebinned the cone-beam sinogram to parallel beam geometry for you and below you can find the code to import the sinogram data. Make use of the `iradon(...)` function from scikit.image to reconstruct the sinogram into an image.\n",
        "\n",
        "\n",
        "<font color='blue'>Answer these questions:\n",
        "\n",
        "- What is wrong with this image?\n",
        "- What could be the physical cause (a scanner problem) of this? (Think about all elements contained in a CT system!)\n",
        "- Correct for this artefact on the sinogram; plot the improved image and explain what you did</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_CBrGRgz0dl"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "f=open(\"Abdomen.bin\", 'rb')\n",
        "data = np.fromfile(f, dtype=np.float64)\n",
        "sinogram = np.transpose(np.reshape(data, [360,729]))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jogpZzdgz0dm"
      },
      "source": [
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPeiBs0gz0dm"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIIZDJCkz0dn"
      },
      "source": [
        "### Code for Exercise 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byqv6Aduz0do"
      },
      "source": [
        "***\n",
        "## <font color='blue'>Exercise 4: Build your own forward projector</font>\n",
        "In medical image reconstruction, the name ‘projector’ or ‘forward projector’ is given to an operation\n",
        "which transforms data from image space to projection space (the sinogram). In this exercise, we want\n",
        "you to implement your own projector in Python, as an alternative to the `radon(...)` function. Implement this projector by combining image rotation followed by summation along one axis. You should keep x' and sum along y'.\n",
        "\n",
        "Start with a 256×256 image that you generate with the `shepp_logan_phantom(...)` function from skimage.data. Now use the functions `skimage.transform.rotate(...)` and `np.sum(...)` to perform projections and to build a sinogram. Use 180 projection angles over an angular range of 180 . Also use `radon(...)` to forward project the original image, so we can compare your implementation to the one you try to mimic.\n",
        "\n",
        "\n",
        "<font color='blue'>Show the sinogram obtained with your own projector. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmmJ_Z5dz0dp"
      },
      "source": [
        "from skimage.data import shepp_logan_phantom\n",
        "from skimage.transform import rescale\n",
        "\n",
        "image = shepp_logan_phantom()\n",
        "image = rescale(image, scale=256/400, mode='reflect', multichannel=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obQqcU4Nz0dp"
      },
      "source": [
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VYE_uNtz0dr"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEHDNn4nz0dr"
      },
      "source": [
        "### Code for Exercise 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9MSjYY0z0ds"
      },
      "source": [
        "## 2. Image reconstruction\n",
        "### 2.1 Backprojection\n",
        "The backprojection operation describes the transformation back from projection space to image space and it is the mathematical adjoint of the Radon transform:\n",
        "\n",
        "\\begin{equation}\n",
        "B(x,y) = \n",
        "\\int_0^\\pi R(\\theta,x')d\\theta\n",
        "\\end{equation} \n",
        "\n",
        "Here, $B(x, y)$ represents the backprojected image, and $R(\\theta, x′)$ is the sinogram. For one fixed angle $\\Theta$, the backprojection $B(x, y; \\theta = \\Theta)$ is performed by smearing the values of $R(\\theta = \\Theta, x′)$ along perpendicular lines (Figure 4). If we repeat this operation for all angles $\\theta$, the sum of all $B(x,y;\\theta = \\Theta)$ will form $B(x, y)$.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><img src=\"images/backproj.jpg\" width=\"300\"/><figcaption><center>(a)</center></figcaption></td>\n",
        "    </tr>\n",
        "</table>\n",
        "<center><i>Figure 4: Backprojection of all values of R(θ,x′) to a rotated image for a fixed angle Θ.\n",
        "</i></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mufHaWDNz0ds"
      },
      "source": [
        "***\n",
        "## <font color='blue'>Exercise 5: Build your own backprojector</font>\n",
        "We can backproject the sinogram obtained in the previous exercise by first smearing $R(\\theta = \\theta,x′)$ into a rotated image. When we rotate this image back to the original position and sum over all angles, we obtain a backprojection of the sinogram. Again, use the functions `imrotate(...)` and `sum(...)` to implement a backprojector. Work on the sinogram you created in exercise 2. \n",
        "\n",
        "<font color='blue'>Show following images:\n",
        "- your backprojection for 10 angles over a range of 360◦\n",
        "- your backprojection for 90 angles over a range of 360◦\n",
        "\n",
        "Answer these questions:\n",
        "- What is the difference between the original image and your backprojection image? \n",
        "- How can the backprojection be improved? </font>\n",
        "\n",
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A6wvxPez0dt"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbq3QOdiz0du"
      },
      "source": [
        "### Code for Exercise 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wimQlk8z0dv"
      },
      "source": [
        "## 2.3 Filtered backprojection\n",
        "To understand the origin of the blur in the reconstructed image, take a look at the sampling in the Fourier domain.\n",
        "Take the backprojection from a single angle:\n",
        "\n",
        "\\begin{equation}\n",
        "B(x,y;\\theta=\\Theta) = R(\\theta = \\Theta,x')\n",
        "\\end{equation} \n",
        "\n",
        "$$\\begin{eqnarray}\n",
        "\\mathcal{B}(\\nu_x,\\nu_y;\\theta=\\Theta) &=& \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} B(x,y;\\theta=\\Theta) e^{-2\\pi i(x\\nu_x+y\\nu_y)}dx dy \\\\\n",
        "&=&  \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} R(\\theta=\\Theta,x^\\prime) e^{-2\\pi i(x\\nu_x+y\\nu_y)}dx^\\prime dy^\\prime \\\\\n",
        "&=& \\mathcal{R}(\\theta=\\Theta,\\nu_{x^\\prime}) \\delta(\\nu_{y^\\prime}) \\\\\n",
        "\\end{eqnarray} $$\n",
        "\n",
        "From the central slice theorem (course notes) we know that $\\mathcal{R}(\\theta=\\Theta,\\nu_{x^\\prime})=\\mathcal{F}(\\nu_x,\\nu_y)\\mid_{\\nu_{y^\\prime}=0}$. Thus, **every backprojection along 1 angle is actually equal to one line of the Fourier transform of the original image!** Superimposing all lines and then taking the inverse Fourier transform would result in our blurry backprojection image. In other words, the blur in the reconstructed image arises from the fact that the center of the Fourier space will be oversampled due to the radial sampling. You get an overestimation of the low frequency components and an underestimation of the high frequency components. This is illustrated in figure 5.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><img src=\"images/sampling_fourier.jpg\" width=\"300\"/><figcaption><center>(a)</center></figcaption></td>\n",
        "        <td><img src=\"images/grid.jpg\" width=\"300\"/><figcaption><center>(b)</center></figcaption></td>\n",
        "        <td><img src=\"images/ramp.jpg\" width=\"300\"/><figcaption><center>(c)</center></figcaption></td>\n",
        "</table>\n",
        "<center><i>Figure 5: (a) Sampling of the Fourier space using 20 backprojections. (b) The radial grid on which the Fourier space is sampled. (c) The ramp filtered used to compensate for the oversampling.\n",
        "</i></center>\n",
        "\n",
        "To compensate for the oversampling at lower frequencies, you should use a filter which is proportional to the circumference of a circle defined with radius $\\nu =\\sqrt{\\nu_x^2+\\nu_u^2}$. Proportionality with the circumference is equal to proportionality with the radius. Thus our filter will be $\\nu$, also called a ramp filter (Figure 5(c)). Thanks to the above, we can discriminate three ways to get to our filtered backprojection, of which the second is the simplest and will be used in the next exercise:\n",
        "\n",
        "1. **Projections** $\\rightarrow$ backprojection $\\rightarrow$ 2D FT $\\rightarrow$ filter with 2D ramp filter $\\rightarrow$ 2D IFT $\\rightarrow$ **Filtered reconstructed image**\n",
        "2. **Projections** $\\rightarrow$ 1D FT $\\rightarrow$ filter with 1D ramp filter $\\rightarrow$ 1D IFT $\\rightarrow$ backprojection $\\rightarrow$ **Filtered reconstructed image**\n",
        "3. **Projections** $\\rightarrow$ backprojection $\\rightarrow$ superimposing all lines in correct angle $\\rightarrow$ interpolation to get more uniform grid in 2D FT space $\\rightarrow$ 2D IFT $\\rightarrow$ **Filtered reconstructed image**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QctWCzWZz0dw"
      },
      "source": [
        "***\n",
        "## <font color='blue'>Exercise 6: Filtered backprojection</font>\n",
        "In this exercise, you will have to solve the problem of oversampling with the second method. Work with the sinogram obtained with radon in exercise 4 (Shepp-Logan phantom). Use all 90 angles. First you will have to transform the sinogram to Fourier space. Next, filter your projection data using a ramp filter. After returning to sinogram space with an inverse Fourier transform, backproject the filtered sinogram using your backprojector from the previous exercise. Compare your result to the result of applying `iradon(...,‘Ramp’)` to your unfiltered sinogram data. Also compare with your own backprojector without filtering.\n",
        "\n",
        "### Remark\n",
        "In order to generate a ramp filter, use the given function below.\n",
        "\n",
        "<font color='blue'> \n",
        "Plot an image of both your own filtered and unfiltered reconstructions and the iradon-backprojection. Also show the original and filtered sinograms. Is the result better with filtering? Limit the number of angles to 20. What happens now?</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqVATzgVz0dw"
      },
      "source": [
        "import math\n",
        "\n",
        "def rampfilter(len):\n",
        "    # Returns the Fourier Transform of the filter which will be \n",
        "    # used to filter the projections\n",
        "    # INPUT ARGS:   len    - the length of the projections\n",
        "    # OUTPUT ARGS:  filt   - the filter to use on the projections\n",
        "    nextpow2 = math.ceil(math.log2(abs(2*len)))\n",
        "    order = max(64,pow(2,nextpow2))\n",
        "    filt = np.arange(0,order+1,2)/order\n",
        "    w = 2*math.pi*np.arange(filt.shape[0])/order # frequency axis up to Nyquist \n",
        "    filt[np.where(w>math.pi)] = 0 # Crop the frequency response\n",
        "    filt_symm = np.zeros([order,1])\n",
        "    filt_symm[0:filt.shape[0],0] = filt\n",
        "    filt_symm[filt.shape[0]:,0] = np.flip(filt)[0:-2]\n",
        "    return (filt_symm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VbIJ_iXz0dx"
      },
      "source": [
        "<font color='red'> SOLUTION: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQdjmw2lz0dy"
      },
      "source": [
        "YOUR ANWER TO THE QUESTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx1v1WKUz0dz"
      },
      "source": [
        "### Code for Exercise 6"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}