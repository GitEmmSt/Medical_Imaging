{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitEmmSt/Medical_Imaging/blob/main/Practical_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQf15uYyt--O",
        "outputId": "165767d3-a4d3-4bc8-b2b0-2c106d0fc8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Medical Imaging/practical_session_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmtfqAiLwPTY",
        "outputId": "2bde413d-bd9e-4e59-80d5-aa323f71cf10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Medical Imaging/practical_session_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbZB_4lQt--S"
      },
      "source": [
        "#  Medical Imaging \n",
        "##  Practical session 4: Image Processing - Part I \n",
        "### Image Enhancement and Filtering\n",
        "### 23rd November 2021\n",
        "***\n",
        "**Jakub Ceranka, Sebastian Amador Sanchez, Jef Vandemeulebroucke\\\n",
        "Department of Electronics and Informatics (ETRO)\\\n",
        "Vrije Universitet Brussel, Pleinlaan 2, B-1050 Brussels, Belgium**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TK79Bv3t--k"
      },
      "source": [
        "<font color=blue>Insert students names and IDs here</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3FkolHSt--v"
      },
      "source": [
        "## Introduction\n",
        "For more information on the following concepts see the lecture recordings, course slides and the related study material.\n",
        "\n",
        "### Purpose\n",
        "The goal of this exercise session is to obtain an insight in the image enhancement and filtering operations commonly applied in medical image processing.\n",
        "\n",
        "\n",
        "### BraTS dataset\n",
        "You will be working with images obtained from the [*Brain Tumor Segmentation (BRATS) Challenge*](http://www.braintumorsegmentation.org), which contains the scans of multiple glioma cases. \n",
        "Gliomas are a type of brain tumor that originate in the glial cells that surround the neurons. They are characterized by having various heterogeneous histological sub-regions. Therefore, they have varying intensity profiles. Consequently, to properly visualize them multimodal MRI scans have to be employed, making multimodal segmentation of brain tumors a major challenge in medical image analysis.\n",
        "\n",
        "<img src=\"./images/brats.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "**(A)** Whole tumor visible in T2-FLAIR **(B)** Tumor core visible in T2 **(C)** Enhancing tumor (blue) and necrotic component (green) visible in T1-Contrast **(D)** Tumor sub-regions.\n",
        "\n",
        "You DO NOT have to download the dataset, the images that you will use are included in this practical session. These images were artifically corrupted so that you can apply enhancing and denoising techniques:\n",
        "- T1c image was corrupted with low contrast\n",
        "- T2 image was corrupted with salt-and-pepper noise\n",
        "- Flair image was corrupted with MR bias field signal\n",
        "\n",
        "At the end of this session, it is exepected that you obtain enhanced and noise-free images where you can apply segmentation algorithms (Practical session 5: Image segmentation).\n",
        "\n",
        "### Instructions\n",
        "The jupyter notebook should be submitted as the report by teams of two using assignment functionality of Ufora.\n",
        "\n",
        "Please complete this notebook and upload the following before the deadline **7th December, 2021, at 23:59**:\n",
        "- the notebook in *.ipynb* format\n",
        "- the executed notebook in *.html* format (File --> Download As --> HTML)\n",
        "\n",
        "The report should contain concise answers to the questions (in specified cells), python code and plotted figures.\n",
        "For this practical session, **we do not** require a separate written report in *.pdf* format.\n",
        "\n",
        "This is the first session of a two-parts practicum. Therefore, you will have to save the resultant images for the following session. If you do not manage to generate the desired enhanced and noise-free images, these will be provided in the next session.\n",
        "\n",
        "\n",
        "#### Questions:  [jceranka@etrovub.be](mailto:jceranka@etrovub.be), [samadors@etrovub.be](mailto:samadors@etrovub.be)\n",
        "\n",
        "### Required modules\n",
        "Before starting make sure you have installed the following libraries:\n",
        "\n",
        "- ```SimpleITK``` -> Read and write images\n",
        "- ```numpy``` -> Operation with arrays\n",
        "- ```matplotlib``` -> Plot images\n",
        "- ```skimage``` -> Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21uGI9ZKt--3"
      },
      "source": [
        "# 1. Image Enhancement\n",
        "## 1.1 The image histogram\n",
        "The histogram is a representation of how many pixels have a certain intensity in the corresponding image. In image processeing, it facilitates the identification of image acquisition issues, for example:\n",
        "\n",
        "- **Over and under exposure:** Are intensity values spread out (good) or clustered (bad)?\n",
        "\n",
        "<img src=\"./images/hist_exposure.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "- **Contrast:** In the image, are there many distinct intensity values (high contrast) or the image uses few intensity values (low contrast)? A \"normal\" contrast is when intensity values are widely spread and there is a large difference between min and max intensity values. \n",
        "\n",
        "<img src=\"./images/hist_contrast.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "- **Dynamic range:** Related to the number of distinct pixels in the image.\n",
        "\n",
        "<img src=\"./images/hist_dyn_range.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "Unlike previous examples, medical images, can however have a large intensity range, or even floating point intensities. This yields very large histograms and makes the pixel count per intensity impractical. \n",
        "\n",
        "<img src=\"./images/hist_mri.png\" alt=\"drawing\" width=\"600\"/>\n",
        "\n",
        "Therefore, in practice intensities are usually binned, i.e. grouped in a reduced number of bins with similar intensity.\n",
        "\n",
        "## 1.2 Image enhancement\n",
        "\n",
        "We shall discuss two ways of contrast improvement: \n",
        "\n",
        "1. [Linear contrast mapping](http://homepages.inf.ed.ac.uk/rbf/HIPR2/stretch.htm) or histogram stretching. It involves a linear transformation on the image intensities, such that the transformed intensities cover to the full range.\n",
        "2. [Histogram equalisation](https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html). In this case, the aim is to obtain a uniform histogram, in which all intensities are equally represented. This can be done by applying a nonlinear transformation on the image intensities. It can be shown that the transform corresponds to the cumulative histogram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb-xZghMt--6"
      },
      "source": [
        "## Exercise 1.1: Linear contrast mapping\n",
        "\n",
        "\n",
        "- Start by reading the image \"BraTS2021_01666_t1ce.mha\" from the folder \"BraTS2021_01666\" with the command [```ReadImage(path_to_image)```](https://simpleitk.readthedocs.io/en/master/IO.html). \n",
        "- Visualize the image, first convert it to an array using ```sitk.GetArrayFromImage(image)```. Next, employ [```imshow(array)```](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html) to plot the image. \n",
        "- Afterwards, use [```hist(image, bins)```](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html) from ```matplotlib``` with ```bins=64``` to view the histogram. \n",
        "\n",
        "Remember that ```SimpleITK``` returns an ITK object, you will have to convert the image to an array before using '```imshow(image)```' and '```hist(image, bins)```'.\n",
        "\n",
        "- Write a function that performs linear histogram stretching (see course slides). Look at the result and its histogram with 64 bins. Compare with the histogram of the original.\n",
        "\n",
        "To built the function:\n",
        "1. Instead of using the minimum and maximum intensity values, start by obtaining the percentiles (P5 and P95) of the image array using [```np.percentile```](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html).\n",
        "2. [Clip](https://numpy.org/doc/stable/reference/generated/numpy.clip.html) the image array employing the values obtained previously. In other words, clipping will set all values below the P5 to 0, and all values above P95 to 1.\n",
        "3. Apply the linear stretching transformation to the clipped image using the percentile values as min and max intensities (P5 and P95 respectively).\n",
        "\n",
        "## Exercise 1.2: Histogram equalization\n",
        "\n",
        "- Create a function that implements histogram equalization (see course slides) to the original image using [```np.histogram```](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html). Look to the new histogram using 64 bins. \n",
        "\n",
        "To built the function:\n",
        "1. Retrieve the histogram and the respective bin edges employing ```np.histogram```. You will have to apply ```.ravel()``` to the image array to correctly obtain the values.\n",
        "2. Calculate the center of the bin edges.\n",
        "3. Determine the cumulative histogram using [```.cumsum()```](https://numpy.org/devdocs/reference/generated/numpy.cumsum.html)\n",
        "4. Re-scale the cumulative histogram between 0 and 1 by dividing with the max value of the cumulative histogram.\n",
        "5. Use [```np.interp()```](https://numpy.org/doc/stable/reference/generated/numpy.interp.html) to apply the new distribution to the image. Since ```np.interp()``` is a one-dimensional linear interpolation, flat the original image array using [```flat```](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flat.html).  Additionally, use the center of the bin edges as the new x-coordinates and the re-scaled cumulative histogram as the new y-coordinates.\n",
        "6. Since the image of point 5 is a 1D-array, reshape it to the original size using [```.reshape(shape)```](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
        "\n",
        "\n",
        "## Report\n",
        "<font color=blue> \n",
        "- Plot a three-by-two image comparison (use ```subplot```) of the image and corresponding histogram for the original image and the ones obtained through the different methods (i.e. linear contrast mapping and histogram equalisation).\n",
        "- In the linear constrast mapping step we have introduced lower and upper intensity percentiles. What is the reason for that?\n",
        "- Look at the output results and their histograms. Compare them with the histogram of the original input image. The histogram of the histogram-equalized output image is not perfectly uniform. What is the reason for this? \n",
        "-  Save the linear stretched image using ```save_image()``` function (provided below).\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFctcSkbt-_J"
      },
      "source": [
        "<font color=blue> Your answer here </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALwndXUht-_L"
      },
      "outputs": [],
      "source": [
        "# Function to save images\n",
        "import os\n",
        "\n",
        "def save_image(array_to_save, name, ground_truth):\n",
        "    '''\n",
        "    This functions converts an array to image domain. Additionally, it creates a subfolder \"Results\", where the \n",
        "    images will be stored.\n",
        "    Inputs:\n",
        "        - array_to_save: Image in array format that will be save. Format: numpy array\n",
        "        - name: Name with which the image is saved. Format: string\n",
        "        - ground_truth: Corresponds to the ORIGINAL image in SimpleITK format. Format: sitk object \n",
        "        \n",
        "    Outputs:\n",
        "        - Folder named \"Results\"\n",
        "        - New image stored in \"Results\"\n",
        "    \n",
        "    '''\n",
        "    # Create image\n",
        "    new_image_sitk = sitk.GetImageFromArray(array_to_save)\n",
        "    \n",
        "    # Copy information from the ground truth to the new image\n",
        "    new_image_sitk.CopyInformation(ground_truth)\n",
        "    \n",
        "    # Create folder to save the resultant images\n",
        "    folder_to_save_images = 'Results'\n",
        "    if not os.path.isdir(folder_to_save_images):\n",
        "        os.mkdir(folder_to_save_images)\n",
        "        \n",
        "    # Write new image\n",
        "    sitk.WriteImage(new_image_sitk, os.path.join(folder_to_save_images, '{}.mha'.format(name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ83YOkVt-_Q"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bao45epHt-_S"
      },
      "source": [
        "# 2. Image Denoising\n",
        "\n",
        "The acquisition of an image is always prone to artifacts that may corrupt or degrade its quality. Examples of them are: noise, blurring and distortion. To reduce the effect of these artifacts, multiple image restoration filters have been proposed. These have been used in medical imaging to enhance or suppress certain features of the images. They may be used either to improve the image quality before reviewing it, or as a preprocessing step to improve the result of further image processing steps such as the segmentation.\n",
        "\n",
        "<img src=\"./images/denoising.png\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "## 2.1 Noise suppression.\n",
        "\n",
        "Image noise can often be assumed to be a high frequency signal. Therefore, many noise reduction approaches filter the high frequency components while preserving the low frequency ones, a common example of these is the 2D-Gaussian filter. \n",
        "\n",
        "Despite the wide use of low pass filtering, this technique has the side effect of blurring the edges of the image. To avoid it, smoothing filters that preserve the edges, such as the non-linear median filter, have been proposed.\n",
        "\n",
        "<img src=\"./images/noise_removal.png\" alt=\"drawing\" width=\"700\"/>\n",
        "\n",
        "## 2.2 Edge enhancement\n",
        "The goal is to enhance the edge contrast of an image in an attempt to improve its apparent sharpness. The resultant edge-image can be added to the original image to improve the visual quality, or can be employed as input in an image segmentation approach. \n",
        "\n",
        "<img src=\"./images/edge_enhancement.png\" alt=\"drawing\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7g0rEIdt-_X"
      },
      "source": [
        "## Exercise 2.1\n",
        "\n",
        "To illustrate image filtering, restore an image which has been distorted with \"Salt and Pepper\" noise.\n",
        "\n",
        "1. Read the ground truth image 'BraTS2021_01666_t2.mha' and the noisy one 'BraTS2021_01666_SP.mha'.\n",
        "2. Apply [Gaussian filtering](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html) to the noisy image with a standard deviation of 1.\n",
        "3. Calculate the filtered and the remaining noise.\n",
        "4. Calculate the root mean squared difference (RMSD) between the obtained filtered image and the ground truth.\n",
        "5. Create an edge map of the obtained filtered image using the [prewitt function](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.prewitt).\n",
        "6. Repeat the process (steps 3-5), for a [median filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.median_filter.html) using a kernel of size 3 and an average filter using [ndimage.convolve](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve) for a kernel of size 3. For the average filter you will have to create your own filter kernel.\n",
        "\n",
        "**hint:** ```RMSD = sqrt([mean_squared_error]```(https://scikit-image.org/docs/dev/api/skimage.metrics.html#skimage.metrics.mean_squared_error)(input_image, filtered_image))\n",
        "\n",
        "\n",
        "## Report\n",
        "<font color=blue>\n",
        "    \n",
        "- Show a three-by-four plot that displays the following for each method: the resultant filtered image, the filtered noise, the noise that remained and the edge map of the filtered image.     \n",
        "- Provide all three values for the RMSD between filtered image and the ground truth. Comment briefly on the results.\n",
        "- What is the interpretation of the difference image with the ground truth and the difference image with the original input image?\n",
        "- Which filter works best in terms of RMSD and why?\n",
        "- Which filter preserves the edges the best?\n",
        "- Save the best result using ```save_image()```.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI33EM4Et-_Z"
      },
      "source": [
        "<font color=blue> Your answer here </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGj-QIC4t-_b"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npPKKwGXt-_f"
      },
      "source": [
        "## 2.3 Intensity non-uniformity correction\n",
        "\n",
        "Non-uniform intensity correction is another common task in image denoising. Grayscale inhomogeneities appear in magnetic resonance (MR) images as systematic changes in the local statistical characteristics of tissues. To reduce these intensity effects Homomorphic Unsharp Masking (HUM) is applied as a post-processing tool.\n",
        "\n",
        "HUM is conceptually straightforward, can be easily implemented and is very fast. It relies on the assumption that if grayscale inhomogeneities are not present in the image, the mean or median in a local window should match the global mean or median of the overall image. This assumption is approximately true when the filter window is large enough to enclose a representative sample of tissues.\n",
        "\n",
        "For a detailed implementation see paper: [*''Optimized Homomorphic Unsharp Masking for MR Grayscale Inhomogeneity Correction'' by Benjamin H. Brinkmann, Armando Manduca and Richard A. Robb, IEEE, 1998*](https://ieeexplore.ieee.org/document/700729)\n",
        "\n",
        "HUM requires the computation of:\n",
        "- The global mean value $\\mu$ of the corrupted image\n",
        "- The local mean values $\\mu_{i,j}$ for each pixel considering a neighbourhood\n",
        "- The HUM corrected/ideal value of a pixel $f_{i,j} = g_{i,j} \\cdot \\frac{\\mu}{\\mu_{i,j}}$, where $g_{i,j}$ is the intensity value of the input image (corrupted/observed image)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8zjrpMKt-_h"
      },
      "source": [
        "## Exercise 2.2\n",
        "\n",
        "Image 'BraTS2021_01666_bias.mha' is a bias corrupted version of 'BraTS2021_01666_flair.mha'. Implement the HUM algorithm in three different ways to compensate for the artifact:\n",
        "\n",
        "1. Implement the algorithm straightforward. Because of the size of your local window you will not be able to correct pixels close to the image borders. Use a moving window of size equal to 41 to calculate the local mean.\n",
        "2. Involve pixels at the image borders by prior padding the image and, thus, enlarging the image. Pad the image with zeros using the half of your window size. To pad the image use [```np.pad```](https://numpy.org/doc/stable/reference/generated/numpy.pad.html)\n",
        "3. Additional to the padding, try to leave out pixels belonging to the background by using a simple global threshold of 10 over the complete image. In other words, in your calculation of the global mean value do not include the pixels below the threshold.\n",
        "\n",
        "We expect that for each case you create a function which has the following backbone:\n",
        "- Calculate global mean image intensity\n",
        "- Get the half value of the window. Make sure it is in 'int' format.\n",
        "- Create a template with np.zeros that has the same size as the biased image.\n",
        "- For points 2 and 3: Before creating the template you will have to pad the biased image with zeros using the half size of your window.\n",
        "- For point 3: Get global mean intensity of the padded biased image applying the threshold.\n",
        "- Iterate over the biased image using the window you set, apply the HUM equation: $f_{i,j} = g_{i,j} \\cdot \\frac{\\mu}{\\mu_{i,j}}$. Store the new pixel in the template image in a correct location.\n",
        "- For points 2 and 3: You will have to return to the original image size. To do so you can use ```crop``` function.\n",
        "\n",
        "\n",
        "After the bias field is removed, calculate the [normalized-root-mean-squared-error](https://scikit-image.org/docs/dev/api/skimage.metrics.html#skimage.metrics.normalized_root_mse) (NRMSE) and the [structural similarity index](https://scikit-image.org/docs/dev/api/skimage.metrics.html#skimage.metrics.structural_similarity)  (SSIM) to evaluate the performance of the denoising algorithms.\n",
        "\n",
        "\n",
        "**Remarks:** \n",
        "\n",
        "- Read the non-bias brain image in '```uint8```' format\n",
        "- Since you will be padding with zeros, use: $\\frac{\\mu}{\\mu_{i,j} + 1}$\n",
        "- Make sure the resultant images are in '```uint8```' format\n",
        "\n",
        "## Report:\n",
        "<font color=blue>\n",
        "    \n",
        "- Plot a one-by-four figure showing the image with bias (BraTS2021_01666_bias.mha) and the three corrected images obtained using the different implementations of the HUM algorithm.\n",
        "- Provide the values for the NRMSE and SSIM between the three corrected images and the ground truth (BraTS2021_01666_flair.mha).\n",
        "- Which case had a better performance? Why? Save the best result using ```save_image()```.\n",
        "    \n",
        "     </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_ilyXGJt-_h"
      },
      "source": [
        "<font color=blue> Your answer here </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WndXj5znt-_i"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1gEO_HVt-_j"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Practical_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}